{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06432f9-334d-4a7c-9121-c0ab2a9f3a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0dev4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import sqlite3\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import teehr\n",
    "from teehr.evaluation.spark_session_utils import create_spark_session\n",
    "\n",
    "teehr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0f3d82-42db-43ea-b914-7740383e462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION_ID_PREFIX = \"nrds22\"\n",
    "CONFIGURATION_NAME = \"nrds_v22_cfenom_short_range\"\n",
    "NGEN_OUTPUT_DIR = \"/data/datastream_output/vpu16/ngen-run\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31bd5f-5227-4628-aea7-2621f841f5dd",
   "metadata": {},
   "source": [
    "### Create the crosswalk where USGS gages exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683795af-4382-405d-9dcd-c0b75cd73fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gages_from_hydrofabric(folder_to_eval):\n",
    "    \"\"\"\n",
    "    Get the gages from the hydrofabric.\n",
    "\n",
    "    Ref: https://github.com/JoshCu/ngiab_eval/blob/2e8fd96b21a369bb93b2a491b0c303a4018a290e/ngiab_eval/core.py\n",
    "    \"\"\"\n",
    "    # search inside the folder for _subset.gpkg recursively\n",
    "    gpkg_file = None\n",
    "    config_dir = os.path.join(folder_to_eval,\"config\")\n",
    "    for root, dirs, files in os.walk(config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".gpkg\"):\n",
    "                gpkg_file = os.path.join(root, file)\n",
    "                break\n",
    "\n",
    "    if gpkg_file is None:\n",
    "        raise FileNotFoundError(f\"No subset.gpkg file found in folder: {folder_to_eval}\")\n",
    "\n",
    "    # figure out if the hf is v20.1 or v2.2\n",
    "    # 2.2 has a pois table, 20.1 does not\n",
    "    with sqlite3.connect(gpkg_file) as conn:\n",
    "        results = conn.execute(\n",
    "            \"SELECT count(*) FROM gpkg_contents WHERE table_name = 'pois'\"\n",
    "        ).fetchall()\n",
    "\n",
    "    if results[0][0] == 0:\n",
    "        with sqlite3.connect(gpkg_file) as conn:\n",
    "            results = conn.execute(\n",
    "                \"SELECT id, rl_gages FROM flowpath_attributes WHERE rl_gages IS NOT NULL\"\n",
    "            ).fetchall()     \n",
    "            # Fixme Take only the first result if a gage shows up more than once.\n",
    "            # Should be fixed upstream in hydrofabric with only error handling here.\n",
    "            results = [(r[0], r[1].split(\",\")[0]) for r in results]\n",
    "    else:\n",
    "        with sqlite3.connect(gpkg_file) as conn:\n",
    "            results = conn.execute(\n",
    "                \"SELECT id, gage FROM 'flowpath-attributes' WHERE gage IS NOT NULL\"\n",
    "            ).fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ed3158-91a7-489e-9bac-b0a84d05b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 496 ms, total: 735 ms\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This creates a list of tuples\n",
    "gage_list = get_gages_from_hydrofabric(NGEN_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194b6aad-e215-4931-a978-acfce67c34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngen_gages_df = pd.DataFrame(gage_list, columns=[\"secondary_location_id\", \"primary_location_id\"])\n",
    "ngen_gages_df[\"primary_location_id\"] = \"usgs-\" + ngen_gages_df[\"primary_location_id\"].astype(str)\n",
    "ngen_gages_df[\"secondary_location_id\"] = ngen_gages_df.secondary_location_id.str.replace(\"wb\", LOCATION_ID_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d473d502-ddc4-49bf-98a2-fa71c77be06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secondary_location_id</th>\n",
       "      <th>primary_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nrds22-2877056</td>\n",
       "      <td>usgs-10251980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nrds22-2877002</td>\n",
       "      <td>usgs-10251890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nrds22-2875761</td>\n",
       "      <td>usgs-10247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nrds22-2880088</td>\n",
       "      <td>usgs-10249190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrds22-2888411</td>\n",
       "      <td>usgs-10245800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  secondary_location_id primary_location_id\n",
       "0        nrds22-2877056       usgs-10251980\n",
       "1        nrds22-2877002       usgs-10251890\n",
       "2        nrds22-2875761       usgs-10247200\n",
       "3        nrds22-2880088       usgs-10249190\n",
       "4        nrds22-2888411       usgs-10245800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngen_gages_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907dc0af-211b-4e1d-8a5a-c62bdaa62034",
   "metadata": {},
   "source": [
    "### Add configuration name and append crosswalk to remote warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d96b8b-4739-48dc-a028-e232f0413c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "aws_access_key_id = credentials.access_key\n",
    "aws_secret_access_key = credentials.secret_key\n",
    "aws_region = session.region_name\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key_id\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_access_key\n",
    "os.environ[\"AWS_REGION\"] = aws_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6c8810-c59c-4deb-beff-bc7f7704f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.spark_session_utils:üöÄ Creating Spark session: TEEHR Evaluation\n",
      "INFO:teehr.evaluation.spark_session_utils:‚úÖ Spark local configuration successful!\n",
      "INFO:teehr.evaluation.spark_session_utils:Setting Hadoop's default AWS credentials provider and AWS region\n",
      "INFO:botocore.credentials:Found credentials in environment variables.\n",
      "INFO:teehr.evaluation.spark_session_utils:üîë Using AWS credentials from boto3\n",
      "INFO:teehr.evaluation.spark_session_utils:Configuring Iceberg catalogs...\n",
      "INFO:teehr.evaluation.spark_session_utils:‚öôÔ∏è All settings applied. Creating Spark session...\n",
      "INFO:teehr.evaluation.spark_session_utils:üéâ Spark session created successfully!\n",
      "INFO:teehr.evaluation.evaluation:Using provided Spark session.\n",
      "INFO:teehr.evaluation.evaluation:Active catalog set to local.\n",
      "INFO:teehr.evaluation.evaluation:Found evaluation version 0.6.0 in /data/temp_warehouse/local.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.2 ms, sys: 26.9 ms, total: 68 ms\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = create_spark_session()\n",
    "\n",
    "dir_path = \"/data/temp_warehouse\"\n",
    "\n",
    "ev = teehr.Evaluation(\n",
    "    spark=spark,\n",
    "    dir_path=dir_path,\n",
    "    create_dir=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffce484-3500-4e79-95bf-3a794ae46219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.evaluation:Active catalog set to remote.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RemoteCatalog(warehouse_dir='s3://dev-teehr-iceberg-warehouse/', catalog_name='iceberg', namespace_name='teehr', catalog_type='rest', catalog_uri='http://iceberg-rest:8181')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.set_active_catalog(\"remote\")\n",
    "ev.active_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2a4551a-f894-4995-b7f5-f62a6fec48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables.base_table:Loading files from iceberg.teehr.configurations.\n",
      "INFO:teehr.evaluation.read:Reading files from iceberg.teehr.configurations.\n",
      "INFO:teehr.evaluation.tables.domain_table:Validating 1 objects before adding to configurations table\n",
      "INFO:teehr.evaluation.validate:Validating DataFrame against schema.\n",
      "INFO:teehr.evaluation.tables.domain_table:Adding 1 objects to configurations table\n",
      "INFO:teehr.evaluation.tables.domain_table:Validating configurations table after adding 1 objects\n",
      "INFO:teehr.evaluation.validate:Validating DataFrame against schema.\n"
     ]
    }
   ],
   "source": [
    "# Add configuration name?\n",
    "ev.configurations.add(\n",
    "    [\n",
    "        teehr.Configuration(\n",
    "            name=CONFIGURATION_NAME,\n",
    "            type=\"secondary\",\n",
    "            description=\"POC version of DataStream forecasts, hydrofabric v.2.2, CFE-NOM\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8e24f0-ef5a-4752-9f87-aa30cc841e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables.base_table:Loading files from iceberg.teehr.locations.\n",
      "INFO:teehr.evaluation.read:Reading files from iceberg.teehr.locations.\n"
     ]
    }
   ],
   "source": [
    "teehr_locations = ev.locations.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e792284d-24ce-40e7-99c8-00c145b78c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngen_gages_df_clip = ngen_gages_df[ngen_gages_df.primary_location_id.isin(teehr_locations[\"id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1194630-c927-4a98-8ec8-f75878beddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngen_gages_df_clip.to_parquet(\"/data/datastream_output/vpu16/nrds_usgs_xwalk.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a560da6-f298-4af8-9928-bfd54f53845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables.base_table:Loading files from iceberg.teehr.location_crosswalks.\n",
      "INFO:teehr.evaluation.read:Reading files from iceberg.teehr.location_crosswalks.\n",
      "INFO:teehr.loading.location_crosswalks:Converting location crosswalks data from: /data/datastream_output/vpu16/nrds_usgs_xwalk.parquet\n",
      "INFO:teehr.evaluation.validate:Validating DataFrame against schema.\n",
      "INFO:teehr.evaluation.extract:Converted 1 files.\n",
      "INFO:teehr.evaluation.read:Reading files from /data/temp_warehouse/local/cache/loading/location_crosswalks.\n",
      "INFO:teehr.evaluation.validate:Enforcing warehouse schema.\n",
      "INFO:teehr.evaluation.validate:Enforcing foreign key constraints.\n",
      "INFO:teehr.evaluation.tables.base_table:Loading files from iceberg.teehr.locations.\n",
      "INFO:teehr.evaluation.read:Reading files from iceberg.teehr.locations.\n",
      "INFO:teehr.evaluation.tables.base_table:Loading files from iceberg.teehr.location_crosswalks.\n",
      "INFO:teehr.evaluation.read:Reading files from iceberg.teehr.location_crosswalks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 ms, sys: 14.9 ms, total: 64.6 ms\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ev.location_crosswalks.load_parquet(in_path=\"/data/datastream_output/vpu16/nrds_usgs_xwalk.parquet\", write_mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c3d15-45b2-4d11-8b88-a7c92e014d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
