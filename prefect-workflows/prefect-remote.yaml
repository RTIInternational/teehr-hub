# Welcome to your prefect.yaml file! You can you this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: teehr-hub
prefect-version: 3.4.24

# build section allows you to manage and build docker images
build: null

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull: null

# the definitions section allows you to define reusable components for your deployments
definitions:
  dir_path: &dir_path "/data/spark-temp"
  log_level: &log_level INFO
  tags: &common_tags
    - k8s
  work_pool: &work_pool
    name: kubernetes-pool
    job_variables:
      image: "{{ $PREFECT_TEEHR_IMAGE }}"
      image_pull_policy: Always
      namespace: "{{ $TEEHR_NAMESPACE }}"
      finished_job_ttl: 300
      pod_watch_timeout_seconds: 300
      service_account_name: prefect-job
      env:
        PREFECT_LOGGING_LEVEL: *log_level
        TEEHR_SPARK_IMAGE: "{{ $TEEHR_SPARK_IMAGE }}"
        TEEHR_NAMESPACE: "{{ $TEEHR_NAMESPACE }}"
        PREFECT_LOGGING_EXTRA_LOGGERS: teehr
        # Start Local Only
        # AWS_ACCESS_KEY_ID: "{{ $AWS_ACCESS_KEY_ID }}"
        # AWS_SECRET_ACCESS_KEY: "{{ $AWS_SECRET_ACCESS_KEY }}"
        # REMOTE_CATALOG_S3_ENDPOINT: "{{ $REMOTE_CATALOG_S3_ENDPOINT }}"
        # REMOTE_CATALOG_S3_PATH_STYLE_ACCESS: "{{ $REMOTE_CATALOG_S3_PATH_STYLE_ACCESS }}"
        # End Local Only
        AWS_REGION: "{{ $AWS_REGION }}"
        REMOTE_CATALOG_REST_URI: "{{ $REMOTE_CATALOG_REST_URI }}"
        REMOTE_CATALOG_TYPE: "{{ $REMOTE_CATALOG_TYPE }}"
        REMOTE_WAREHOUSE_S3_PATH: "{{ $REMOTE_WAREHOUSE_S3_PATH }}"
        IN_CLUSTER: "{{ $IN_CLUSTER }}"
      node_selector:
        teehr-hub/nodegroup-name: spark-r5-4xlarge
      tolerations:
        - key: teehr-hub/dedicated
          operator: Equal
          value: worker
          effect: NoSchedule
        - key: teehr-hub_dedicated
          operator: Equal
          value: worker
          effect: NoSchedule
      cpu_request: "4"
      memory_request: 32Gi

# the deployments section allows you to provide configuration for deploying flows
deployments:
  # Workflows that are configured for the remote cluster
  - name: ingest-usgs-streamflow-obs
    version:
    tags: []
    description: Ingest USGS streamflow data from NWIS
    entrypoint: workflows/ingests/usgs_streamflow_obs.py:ingest_usgs_streamflow_obs
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 8,20 * * *"
      active: true

  - name: ingest-nwm-short-range-streamflow-forecasts
    version:
    tags: []
    description: Ingest NWM short range streamflow forecasts from GCS
    entrypoint: workflows/ingests/nwm_streamflow_forecasts.py:ingest_nwm_streamflow_forecasts
    parameters: {
      "dir_path": *dir_path,
      "nwm_configuration": "short_range"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 7,19 * * *"
      active: true

  - name: ingest-nwm-medium-range-streamflow-forecasts
    version:
    tags: []
    description: Ingest NWM medium range member 1 streamflow forecasts from GCS
    entrypoint: workflows/ingests/nwm_streamflow_forecasts.py:ingest_nwm_streamflow_forecasts
    parameters: {
      "dir_path": *dir_path,
      "nwm_configuration": "medium_range_mem1",
      "output_type": "channel_rt_1"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 6,18 * * *"
      active: true

  - name: ingest-datastream-short-range-cfe-forecasts
    version:
    tags: []
    description: Ingest DataStream streamflow forecasts from S3
    entrypoint: workflows/ingests/datastream_streamflow_forecasts.py:ingest_datastream_forecasts
    parameters: {
      "dir_path": *dir_path,
      "forecast_configuration": "short_range",
      "datastream_name": "cfe_nom"
    }
    work_pool: *work_pool
    schedule:
      cron: "30 10 * * *"
      active: true

  - name: ingest-datastream-medium-range-cfe-forecasts
    version:
    tags: []
    description: Ingest DataStream streamflow forecasts from S3
    entrypoint: workflows/ingests/datastream_streamflow_forecasts.py:ingest_datastream_forecasts
    parameters: {
      "dir_path": *dir_path,
      "forecast_configuration": "medium_range",
      "datastream_name": "cfe_nom"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 11 * * *"
      active: true

  - name: ingest-datastream-short-range-lstm-forecasts
    version:
    tags: []
    description: Ingest DataStream streamflow forecasts from S3
    entrypoint: workflows/ingests/datastream_streamflow_forecasts.py:ingest_datastream_forecasts
    parameters: {
      "dir_path": *dir_path,
      "forecast_configuration": "short_range",
      "datastream_name": "lstm_0"
    }
    work_pool: *work_pool
    schedule:
      cron: "30 11 * * *"
      active: true

  - name: ingest-datastream-medium-range-lstm-forecasts
    version:
    tags: []
    description: Ingest DataStream streamflow forecasts from S3
    entrypoint: workflows/ingests/datastream_streamflow_forecasts.py:ingest_datastream_forecasts
    parameters: {
      "dir_path": *dir_path,
      "forecast_configuration": "medium_range",
      "datastream_name": "lstm_0"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 12 * * *"
      active: true

  - name: ingest-nwps-rfc-streamflow-forecasts
    version:
    tags: []
    description: Ingest NWPS RFC streamflow forecasts from NOAA servers
    entrypoint: workflows/ingests/nwps_rfc_streamflow_forecasts.py:ingest_nwps_rfc_forecasts
    parameters: {
      "dir_path": *dir_path
    }
    work_pool: *work_pool
    schedule:
      cron: "15 * * * *"
      active: true

  - name: update-joined-forecast-table
    version:
    tags: []
    description: Create the joined forecast timeseries table
    entrypoint: workflows/metrics/update_joined_forecasts.py:update_joined_forecast_table
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 9,21 * * *"
      active: true

  - name: update-forecast-metrics-table
    version:
    tags: []
    description: Create the forecast metrics table
    entrypoint: workflows/metrics/update_forecast_metrics.py:update_forecast_metrics_table
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 10,22 * * *"
      active: true

  - name: routine-table-maintenance
    version:
    tags: []
    description: Run routine Iceberg table maintenance (expire snapshots, remove orphan files, compact data files, rewrite manifests)
    entrypoint: workflows/maintenance/routine_table_maintenance.py:routine_table_maintenance
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 4 * * 0"
      active: true
