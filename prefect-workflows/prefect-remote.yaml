# Welcome to your prefect.yaml file! You can you this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: teehr-hub
prefect-version: 3.4.24

# build section allows you to manage and build docker images
build: null

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull: null

# the definitions section allows you to define reusable components for your deployments
definitions:
  dir_path: &dir_path "/data/temp_warehouse"
  log_level: &log_level INFO
  tags: &common_tags
    - k8s
  work_pool: &work_pool
    name: kubernetes-pool
    job_variables:
      image: "{{ $PREFECT_TEEHR_IMAGE }}"
      image_pull_policy: Always
      namespace: "{{ $TEEHR_NAMESPACE }}"
      finished_job_ttl: 300
      pod_watch_timeout_seconds: 300
      service_account_name: prefect-job
      env:
        PREFECT_LOGGING_LEVEL: *log_level
        TEEHR_SPARK_IMAGE: "{{ $TEEHR_SPARK_IMAGE }}"
        TEEHR_NAMESPACE: "{{ $TEEHR_NAMESPACE }}"
        PREFECT_LOGGING_EXTRA_LOGGERS: teehr
        # Start Local Only
        # AWS_ACCESS_KEY_ID: "{{ $AWS_ACCESS_KEY_ID }}"
        # AWS_SECRET_ACCESS_KEY: "{{ $AWS_SECRET_ACCESS_KEY }}"
        # REMOTE_CATALOG_S3_ENDPOINT: "{{ $REMOTE_CATALOG_S3_ENDPOINT }}"
        # REMOTE_CATALOG_S3_PATH_STYLE_ACCESS: "{{ $REMOTE_CATALOG_S3_PATH_STYLE_ACCESS }}"
        # End Local Only
        AWS_REGION: "{{ $AWS_REGION }}"
        REMOTE_CATALOG_REST_URI: "{{ $REMOTE_CATALOG_REST_URI }}"
        REMOTE_CATALOG_TYPE: "{{ $REMOTE_CATALOG_TYPE }}"
        REMOTE_WAREHOUSE_S3_PATH: "{{ $REMOTE_WAREHOUSE_S3_PATH }}"
        IN_CLUSTER: "{{ $IN_CLUSTER }}"
      node_selector:
        teehr-hub/nodegroup-name: spark-r5-4xlarge
      tolerations:
        - key: teehr-hub/dedicated
          operator: Equal
          value: worker
          effect: NoSchedule
        - key: teehr-hub_dedicated
          operator: Equal
          value: worker
          effect: NoSchedule

# the deployments section allows you to provide configuration for deploying flows
deployments:
  # Workflows that are configured for the remote cluster
  - name: ingest-usgs-streamflow-obs
    version:
    tags: []
    description: Ingest USGS streamflow data from NWIS
    entrypoint: workflows/usgs_streamflow_obs.py:ingest_usgs_streamflow_obs
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 8,20 * * *"
      active: true

  - name: ingest-nwm-short-range-streamflow-forecasts
    version:
    tags: []
    description: Ingest NWM short range streamflow forecasts from GCS
    entrypoint: workflows/nwm_streamflow_forecasts.py:ingest_nwm_streamflow_forecasts
    parameters: {
      "dir_path": *dir_path,
      "nwm_configuration": "short_range"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 7,19 * * *"
      active: true

  - name: ingest-nwm-medium-range-streamflow-forecasts
    version:
    tags: []
    description: Ingest NWM medium range member 1 streamflow forecasts from GCS
    entrypoint: workflows/nwm_streamflow_forecasts.py:ingest_nwm_streamflow_forecasts
    parameters: {
      "dir_path": *dir_path,
      "nwm_configuration": "medium_range_mem1",
      "output_type": "channel_rt_1"
    }
    work_pool: *work_pool
    schedule:
      cron: "0 6,18 * * *"
      active: true

  - name: ingest-datastream-forecasts
    version:
    tags: []
    description: Ingest DataStream streamflow forecasts from S3
    entrypoint: workflows/datastream_streamflow_forecasts.py:ingest_datastream_forecasts
    parameters: {
      "dir_path": *dir_path,
    }
    work_pool: *work_pool
    # schedule:
    #   cron: "0 10 * * *"
    #   active: true

  - name: update-joined-forecast-table
    version:
    tags: []
    description: Create the joined forecast timeseries table
    entrypoint: workflows/update_joined_forecasts.py:update_joined_forecast_table
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 9,21 * * *"
      active: true

  - name: update-forecast-metrics-table
    version:
    tags: []
    description: Create the forecast metrics table
    entrypoint: workflows/update_forecast_metrics.py:update_forecast_metrics_table
    parameters: {"dir_path": *dir_path}
    work_pool: *work_pool
    schedule:
      cron: "0 10,22 * * *"
      active: true