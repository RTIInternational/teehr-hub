apiVersion: v1
kind: Pod
spec:
  terminationGracePeriodSeconds: 60
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    # supplementalGroups: [1000]
  containers:
  - name: spark-kubernetes-executor
    securityContext:
      runAsUser: 1000
      runAsGroup: 1000
      allowPrivilegeEscalation: false
    lifecycle:
      preStop:
        exec:
          # Allow Spark to decommission gracefully - SIGTERM triggers Spark's 
          # built-in decommissioning which migrates shuffle data and RDD blocks
          command: ["/bin/sh", "-c", "sleep 30"]
    volumeMounts:
    - name: data-nfs
      mountPath: /data
    # env:
    # - name: SPARK_USER
    #   value: "spark"
  volumes:
  - name: data-nfs
    persistentVolumeClaim:
      claimName: data-nfs
  tolerations:
  - effect: "NoSchedule"
    key: "teehr-hub/dedicated"
    operator: "Equal"
    value: "worker"
  - effect: "NoSchedule"
    key: "teehr-hub_dedicated"
    operator: "Equal"
    value: "worker"
  nodeSelector:
    teehr-hub/nodegroup-name: spark-r5-4xlarge-spot